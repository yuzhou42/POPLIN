{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we extract a uniformly sampled dataset of the environments to benchmark model accuracy off-sample for halfcheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     110
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import dotmap\n",
    "from glob import glob\n",
    "from dmbrl.modeling.models.NN import NN\n",
    "from dmbrl.modeling.models.BNN import BNN\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from time import localtime, strftime\n",
    "\n",
    "from scipy.io import savemat\n",
    "from dotmap import DotMap\n",
    "\n",
    "from dmbrl.misc.DotmapUtils import get_required_argument\n",
    "from dmbrl.misc.Agent import Agent\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import argparse\n",
    "import pprint\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from dotmap import DotMap\n",
    "\n",
    "from dmbrl.misc.MBExp import MBExperiment\n",
    "from dmbrl.controllers.MPC import MPC\n",
    "from dmbrl.config import create_config\n",
    "from dmbrl.misc import logger\n",
    "from io import StringIO\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def process_config_txt(config_txt,log_file):\n",
    "    tf.reset_default_graph() \n",
    "    with open(config_txt,'r') as inf:\n",
    "        k = inf.read()\n",
    "        l = re.search(r'<.*<.*.>.*>',k).group(0)\n",
    "        env_name = l.split('<')[-1].split('.')[0]\n",
    "        print(env_name)\n",
    "        readable = re.sub(r'<.*>',\"\\\"\\\"\",k)\n",
    "    #     k = k.replace('0x','')\n",
    "    #     k = k.replace('<',\"\\\"\")\n",
    "    #     k = k.replace('>',\"\\\"\")\n",
    "\n",
    "        dict_from_file = eval(readable)\n",
    "        init_cfg = dict_from_file['ctrl_cfg']['prop_cfg']['model_init_cfg']\n",
    "        activation = init_cfg['activation']\n",
    "        network_shape = init_cfg['network_shape']\n",
    "        weight_decays = init_cfg['weight_decays']\n",
    "        lr = init_cfg['lr']\n",
    "        overrides = [['ctrl_cfg.prop_cfg.model_init_cfg.activation', str(activation)], \n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.network_shape', str(network_shape)], \n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.lr',str(lr)], \n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.weight_decays',str(weight_decays)], \n",
    "                     ['exp_cfg.exp_cfg.ntrain_iters', '50'],\n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.load_model','True'],\n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.model_dir',log_file],\n",
    "                    ['exp_cfg.exp_cfg.ntrain_iters',\"1\"]]\n",
    "        logdir = 'log'\n",
    "        ctrl_args = [['opt-type', 'CEM'], ['model-type', 'PE'], ['prop-type', 'E']]\n",
    "        \n",
    "        \n",
    "        return dict_from_file,overrides,logdir,ctrl_args,env_name\n",
    "\n",
    "\n",
    "for environment_name in ['ant','halfcheetah','hopper']:\n",
    "    # log_dir = '/home/motion/Joao/classes/ece598sg-mps/final_project_ece598/POPLIN/log/test_hopper/'\n",
    "    # log_dir = '/home/motion/Joao/classes/ece598sg-mps/final_project_ece598/POPLIN/log/test_halfcheetah/'\n",
    "    # log_dir = '/home/motion/Joao/classes/ece598sg-mps/final_project_ece598/POPLIN/log/test_ant/'\n",
    "    log_dir = '/home/motion/Joao/classes/ece598sg-mps/final_project_ece598/POPLIN/log/test_{}/'.format(environment_name)\n",
    "    config_file = glob(log_dir+'*.txt')[0]\n",
    "    # with open(config_raw[0],'r') as inf:\n",
    "    #     k = inf.read()\n",
    "    #     l = re.search(r'<.*<.*.>.*>',k).group(0)\n",
    "    #     env = l.split('<')[-1].split('.')[0]\n",
    "    #     readable = re.sub(r'<.*>',\"\\\"\\\"\",k)\n",
    "    # #     k = k.replace('0x','')\n",
    "    # #     k = k.replace('<',\"\\\"\")\n",
    "    # #     k = k.replace('>',\"\\\"\")\n",
    "\n",
    "    #     dict_from_file = eval(readable)\n",
    "    processed_dict,overrides,logdir,ctrl_args,env_name = process_config_txt(config_file,log_dir)\n",
    "    ctrl_args = DotMap(**{key: val for (key, val) in ctrl_args})\n",
    "    cfg = create_config(env_name,\"MPC\", ctrl_args, overrides, logdir)\n",
    "    cfg.exp_cfg.exp_cfg.policy = MPC(cfg.ctrl_cfg)\n",
    "\n",
    "\n",
    "    cfg.exp_cfg.misc = copy.copy(cfg)\n",
    "    exp = MBExperiment(cfg.exp_cfg)\n",
    "    if(env_name != 'halfcheetah'):\n",
    "        print('this is ',env_name)\n",
    "        env = exp.env._env.env\n",
    "    else:\n",
    "        print('we are working with {}'.format(env_name))\n",
    "        env = exp.env\n",
    "    # we add a function that allows for arbitrary positioning of the model:\n",
    "    # def place_model(self,init_qpos = [],init_qvel = []):\n",
    "    #     if(len(init_qpos)!= 0):\n",
    "    #         if(len(init_qvel !=0)):\n",
    "    #             qpos = init_qpos\n",
    "    #             qvel = init_qvel\n",
    "    #         else:\n",
    "    #             qpos = self.init_qpos + self.np_random.uniform(size=self.model.nq, low=-.1, high=.1) \n",
    "    #             qvel = self.init_qvel + self.np_random.randn(self.model.nv) * .1\n",
    "    #     else:\n",
    "    #         qpos = self.init_qpos + self.np_random.uniform(size=self.model.nq, low=-.1, high=.1)\n",
    "    #         qvel = self.init_qvel + self.np_random.randn(self.model.nv) * .1\n",
    "    #     self.set_state(qpos, qvel)\n",
    "\n",
    "    #     return self._get_obs()\n",
    "\n",
    "    # env.place_model = place_model\n",
    "    model = env.model\n",
    "\n",
    "    # we then get the model qbounds - and set the qbounds on the joints:\n",
    "\n",
    "    # we then obtain the joint limits and sample 50.000 examples within the limits\n",
    "\n",
    "    # We then set the ranges according to what we saw during all the experiments:\n",
    "\n",
    "    if(env_name == 'halfcheetah'):\n",
    "        high = [9.96128474,0.98984282,56.42344112,1.10883563,0.89405376,0.91599938,0.88814824,\n",
    "                                 1.07776409,0.73160817,10.48143774,4.97410966,13.39867047,\n",
    "                                 25.49660014,31.22417231,\n",
    "                                 24.50860937,31.08020618, 33.91224822,\n",
    "                                 29.45049987] \n",
    "        low = [ 0,-0.60089228,-3.38180708,-0.70808846,-0.94726328,-0.69846955,-1.1664694,-1.25208849,-0.71914243,\n",
    "                                                        -4.62570942,-6.07998072,-10.07353218,-27.25994739,-29.93182322,\n",
    "                                                        -29.46358498, -26.98998881,-32.6241283,-23.90487897]\n",
    "    elif(env_name == 'gym_ant'):\n",
    "        high = [ 2.95740289,0.9999914,0.99982883,0.9998585,0.99980208,0.68677208,1.35133411,\n",
    "                0.6962879,0.09895299,0.68500648,0.09878973,0.69019431,1.36160244,\n",
    "                4.74811162,4.5842259,6.27479401,14.2021727,12.43167361,10.69651593,\n",
    "                17.07403083,18.01675964,17.01246318,14.53401165,17.38114028,14.47999146,\n",
    "                17.0391048,17.98908219]\n",
    "        low = [0.22637723 ,-0.99981976,-0.99996822,-0.99974723,-0.99999862,\n",
    "      -0.68875781,-0.0986322,-0.68763238,-1.35011608,-0.68757495,\n",
    "      -1.35376862,  -0.68970977,  -0.09800097,  -4.14476645,  -4.48196699,\n",
    "      -5.98612387, -13.08248117, -11.78631638, -12.34927498, -17.55141179,\n",
    "     -14.24190613, -17.32666853, -15.94113497, -17.47971411, -17.23695828,\n",
    "     -16.91510594, -14.06285142]\n",
    "    elif(env_name == 'gym_hopper'):\n",
    "        high = [ 1.96040359,14.67674145,  0.24221648,  0.20641022,  0.97567123,  7.98996199,\n",
    "      7.60698399, 34.36266375, 31.65726622, 27.55551616, 25.28091824]\n",
    "        low = [ 1.03056874e-02, -1.56137981e+01, -2.84094996e+00, -2.79574698e+00,\n",
    "     -9.66243311e-01, -7.24971707e+00, -1.22857845e+01, -4.70124229e+01,\n",
    "     -2.94250451e+01, -2.35840978e+01, -2.38191301e+01]\n",
    "\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(100000):\n",
    "    #     pos = np.random.uniform(low = ranges[:,0],high = ranges[:,1])\n",
    "    #     vel = np.random.uniform(low = ranges[:,0],high = ranges[:,1])\n",
    "        env.reset()\n",
    "        vec = np.random.uniform(high = high , \n",
    "                          low = low)\n",
    "    #     if(env_name == 'halfcheetah'):\n",
    "        q_pos = env.init_qpos\n",
    "        rem = len(q_pos)-len(vec) + len(env.init_qvel)\n",
    "        q_pos[rem:env.init_qpos.shape[0]] = vec[rem:env.init_qpos.shape[0]]\n",
    "        q_vel = vec[-len(env.init_qvel):]\n",
    "    #     else:\n",
    "        env.set_state(qpos = q_pos,qvel = q_vel)\n",
    "        init_pos = env._get_obs()\n",
    "        if(env_name == 'gym_ant'):\n",
    "            init_pos = init_pos[:27]\n",
    "\n",
    "    #     print(env._get_obs(),vecs)\n",
    "        act = np.random.uniform(high = env.action_space.high,low = env.action_space.low)\n",
    "        inputs.append(init_pos.tolist()+act.tolist())\n",
    "        output = env.step(act)[0].tolist()\n",
    "        if(env_name == 'gym_ant'):\n",
    "            output = output[:27]\n",
    "        outputs.append(output)\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)\n",
    "    np.save('./gt_datasets/{}/outputs'.format(env_name),outputs)\n",
    "    np.save('./gt_datasets/{}/inputs'.format(env_name),inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = DotMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "network_params.load_model = True\n",
    "network_params.model_dir = '/home/motion/Joao/classes/ece598sg-mps/final_project_ece598/POPLIN/log/test_ant/'\n",
    "network_params.name = 'model'\n",
    "nw = BNN(network_params)\n",
    "nw.finalize(tf.train.AdamOptimizer, {\"learning_rate\": 0.001})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.load('./gt_datasets/gym_ant/outputs.npy')\n",
    "inputs = np.load('./gt_datasets//inputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pred_outs = nw.predict(inputs)\n",
    "\n",
    "diff = outputs - pred_outs[0]\n",
    "diff = np.power(diff,2)\n",
    "(diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating the analysis of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import dotmap\n",
    "from glob import glob\n",
    "from dmbrl.modeling.models.NN import NN\n",
    "from dmbrl.modeling.models.BNN import BNN\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from time import localtime, strftime\n",
    "from scipy.io import savemat\n",
    "from dmbrl.misc.DotmapUtils import get_required_argument\n",
    "from dmbrl.misc.Agent import Agent\n",
    "import numpy as np\n",
    "import pprint\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from dotmap import DotMap\n",
    "from dmbrl.misc.MBExp import MBExperiment\n",
    "from dmbrl.controllers.MPC import MPC\n",
    "from dmbrl.config import create_config\n",
    "from dmbrl.misc import logger\n",
    "from io import StringIO\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the log files:\n",
    "\n",
    "exp_dirs = glob('./results/*/*/*/')\n",
    "\n",
    "oos_errors = []\n",
    "error_stds = []\n",
    "exp_names  = []\n",
    "env_names  = []\n",
    "max_returns = []\n",
    "max_returns_std = []\n",
    "is_errors = []\n",
    "for exp_dir in exp_dirs:\n",
    "    a = 1\n",
    "    seed_dirs = glob(exp_dir+'*/')\n",
    "    environment = exp_dir.split('/')[-2]\n",
    "    exp_name = exp_dir.split('/')[-3]\n",
    "    gt_outputs = np.load('./gt_datasets/{}/outputs.npy'.format(environment))\n",
    "    inputs = np.load('./gt_datasets/{}/inputs.npy'.format(environment))\n",
    "    errors = []\n",
    "    returns = []\n",
    "    for seed_dir in seed_dirs:\n",
    "        tf.reset_default_graph() \n",
    "        network_params = DotMap()\n",
    "        network_params.load_model = True\n",
    "        network_params.model_dir = seed_dir\n",
    "        network_params.name = 'model'\n",
    "        nw = BNN(network_params)\n",
    "        nw.finalize(tf.train.AdamOptimizer, {\"learning_rate\": 0.001})\n",
    "        training_logs = loadmat(seed_dir+'logs.mat')\n",
    "        returns = training_logs['returns'].max()\n",
    "        pred_outs = nw.predict(inputs)\n",
    "        diff = gt_outputs - pred_outs[0]\n",
    "        diff = np.power(diff,2)\n",
    "        errors = diff.mean()\n",
    "        # finally we calculate the in-sample errors:\n",
    "        obs = training_logs['observations']\n",
    "        in_sample_obs = obs[:,:-1,:].reshape(-1,obs.shape[-1])\n",
    "        in_sample_gt = obs[:,1:,:].reshape(-1,obs.shape[-1])\n",
    "        acts = training_logs['actions']\n",
    "        acts = acts.reshape(-1,acts.shape[-1])\n",
    "        in_sample_inputs = np.concatenate((in_sample_obs,acts),axis = 1)\n",
    "        in_preds = nw.predict(in_sample_inputs)\n",
    "        in_sample_diffs = in_sample_gt - in_preds[0]\n",
    "        in_sample_diffs = np.power(in_sample_diffs,2)\n",
    "        in_sample_error = np.mean(in_sample_diffs)\n",
    "        \n",
    "        oos_errors.append(np.mean(errors))\n",
    "#         error_stds.append(np.std(errors))\n",
    "        max_returns.append(np.mean(returns))\n",
    "#         max_returns_std.append(np.std(returns))\n",
    "        exp_names.append(exp_name)\n",
    "        env_names.append(environment)\n",
    "        is_errors.append(in_sample_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = training_logs['observations']\n",
    "in_sample_obs = obs[:,:-1,:].reshape(-1,obs.shape[-1])\n",
    "in_sample_gt = obs[:,1:,:].reshape(-1,obs.shape[-1])\n",
    "acts = training_logs['actions']\n",
    "acts = acts.reshape(-1,acts.shape[-1])\n",
    "in_sample_inputs = np.concatenate((in_sample_obs,acts),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "performance_dataset = pd.DataFrame({'oos_error':oos_errors,'is_error':is_errors,'max_returns':max_returns,'exp_names':exp_names,'env_names':env_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting OOS error vs rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_names = performance_dataset.env_names.unique()\n",
    "for env_name in env_names:\n",
    "    tmp1 = performance_dataset[performance_dataset.env_names == env_name]\n",
    "    exp_names = tmp1.exp_names.unique()\n",
    "    for exp_name in exp_names:\n",
    "        tmp = tmp1[tmp1.exp_names == exp_name]\n",
    "        plt.scatter(tmp.oos_error.values.tolist(),tmp.max_returns.values.tolist(),label = exp_name[6:])\n",
    "        plt.xscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('Out of Sample Error x Max Returns in-sample - {}'.format(env_name))\n",
    "    plt.xlim(left = 1)\n",
    "    plt.ylim(bottom = np.min([0,tmp1.max_returns.min()]))\n",
    "    plt.xlabel('log(Out of Sample MSE)')\n",
    "    plt.ylabel('Max Train Return')\n",
    "    plt.savefig('./figures/Out of Sample Error x Max Returns in-sample - {}.pdf'.format(env_name),bbox_inches = 'tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting IS_ERROR VS OOS_ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_names = performance_dataset.env_names.unique()\n",
    "for env_name in env_names:\n",
    "    tmp1 = performance_dataset[performance_dataset.env_names == env_name]\n",
    "    exp_names = tmp1.exp_names.unique()\n",
    "    for exp_name in exp_names:\n",
    "        tmp = tmp1[tmp1.exp_names == exp_name]\n",
    "        plt.scatter(tmp.is_error.values.tolist(),tmp.oos_error.values.tolist(),label = exp_name[6:])\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('In-sample error x Out of Sample Error - {}'.format(env_name))\n",
    "    plt.xlim(left = 1)\n",
    "    plt.ylim(bottom = 1)\n",
    "    plt.xlabel('log(In Sample MSE)')\n",
    "    plt.ylabel('log(Out of Sample MSE)')\n",
    "    plt.savefig('./figures/In-Sample Error x Out of Sample Error - {}.pdf'.format(env_name),bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting In-sample error vs max_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_names = performance_dataset.env_names.unique()\n",
    "for env_name in env_names:\n",
    "    tmp1 = performance_dataset[performance_dataset.env_names == env_name]\n",
    "    exp_names = tmp1.exp_names.unique()\n",
    "    for exp_name in exp_names:\n",
    "        tmp = tmp1[tmp1.exp_names == exp_name]\n",
    "        plt.scatter(tmp.is_error.values.tolist(),tmp.max_returns.values.tolist(),label = exp_name[6:])\n",
    "        plt.xscale('log')\n",
    "    plt.legend()\n",
    "    plt.title('In-Sample Error x Max Returns in-sample - {}'.format(env_name))\n",
    "    plt.xlim(left = 1)\n",
    "    plt.ylim(bottom = np.min([0,tmp1.max_returns.min()]))\n",
    "    plt.xlabel('log(In-Sample MSE)')\n",
    "    plt.ylabel('Max Train Return')\n",
    "    plt.savefig('./figures/In-Sample Error x Max Returns in-sample - {}.pdf'.format(env_name),bbox_inches = 'tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Videos for the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie file = ./videos/halfcheetah/layer_2x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_2x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_2x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_2x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_2x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_2x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_2x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_2x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_2x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x200_sine/0.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x200_sine/1.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x200_sine/2.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x200_sine/0.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x200_sine/1.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x200_sine/2.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x200_sine/0.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x200_sine/1.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x200_sine/2.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x100_swish/0.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x100_swish/1.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x100_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x100_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x100_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x100_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x100_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x100_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x100_swish/2.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_6x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_6x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_6x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_6x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_6x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_6x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_6x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_6x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_6x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/halfcheetah/layer_4x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_ant/layer_4x200_swish/2.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x200_swish/0.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x200_swish/1.mp4 already exists\n",
      "movie file = ./videos/gym_hopper/layer_4x200_swish/2.mp4 already exists\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import dotmap\n",
    "from glob import glob\n",
    "from dmbrl.modeling.models.NN import NN\n",
    "from dmbrl.modeling.models.BNN import BNN\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from time import localtime, strftime\n",
    "\n",
    "from scipy.io import savemat\n",
    "from dotmap import DotMap\n",
    "\n",
    "from dmbrl.misc.DotmapUtils import get_required_argument\n",
    "from dmbrl.misc.Agent import Agent\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import argparse\n",
    "import pprint\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from dotmap import DotMap\n",
    "\n",
    "from dmbrl.misc.MBExp import MBExperiment\n",
    "from dmbrl.controllers.MPC import MPC\n",
    "from dmbrl.config import create_config\n",
    "from dmbrl.misc import logger\n",
    "from io import StringIO\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def process_config_txt(config_txt,log_file):\n",
    "    tf.reset_default_graph() \n",
    "    with open(config_txt,'r') as inf:\n",
    "        k = inf.read()\n",
    "        l = re.search(r'<.*<.*.>.*>',k).group(0)\n",
    "        env_name = l.split('<')[-1].split('.')[0]\n",
    "        print(env_name)\n",
    "        readable = re.sub(r'<.*>',\"\\\"\\\"\",k)\n",
    "    #     k = k.replace('0x','')\n",
    "    #     k = k.replace('<',\"\\\"\")\n",
    "    #     k = k.replace('>',\"\\\"\")\n",
    "\n",
    "        dict_from_file = eval(readable)\n",
    "        init_cfg = dict_from_file['ctrl_cfg']['prop_cfg']['model_init_cfg']\n",
    "        try:\n",
    "            activation = init_cfg['activation']\n",
    "        except:\n",
    "            activation = 'swish'\n",
    "        try:\n",
    "            network_shape = init_cfg['network_shape']\n",
    "        except:\n",
    "            network_shape = '[200,200,200,200]'\n",
    "        try:\n",
    "            weight_decays = init_cfg['weight_decays']\n",
    "        except:\n",
    "            weight_decays = '[0.000025,0.00005,0.000075,0.000075,0.0001]'\n",
    "        try:\n",
    "            lr = init_cfg['lr']\n",
    "        except:\n",
    "            lr = '0.001'\n",
    "        overrides = [['ctrl_cfg.prop_cfg.model_init_cfg.activation', str(activation)], \n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.network_shape', str(network_shape)], \n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.lr',str(lr)], \n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.weight_decays',str(weight_decays)], \n",
    "                     ['exp_cfg.exp_cfg.ntrain_iters', '50'],\n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.load_model','True'],\n",
    "                     ['ctrl_cfg.prop_cfg.model_init_cfg.model_dir',log_file],\n",
    "                    ['exp_cfg.exp_cfg.ntrain_iters',\"1\"]]\n",
    "        logdir = 'log'\n",
    "        ctrl_args = [['opt-type', 'CEM'], ['model-type', 'PE'], ['prop-type', 'E']]\n",
    "        \n",
    "        \n",
    "        return dict_from_file,overrides,logdir,ctrl_args,env_name\n",
    "\n",
    "\n",
    "# for environment_name in ['ant','halfcheetah','hopper']:\n",
    "exp_dirs = glob('./results/*/*/*/')\n",
    "\n",
    "for exp_dir in exp_dirs[:]:\n",
    "    a = 1\n",
    "    seed_dirs = glob(exp_dir+'*/')\n",
    "    environment = exp_dir.split('/')[-2]\n",
    "    exp_name = exp_dir.split('/')[-3]\n",
    "    gt_outputs = np.load('./gt_datasets/{}/outputs.npy'.format(environment))\n",
    "    inputs = np.load('./gt_datasets/{}/inputs.npy'.format(environment))\n",
    "    errors = []\n",
    "    returns = []\n",
    "    for seed,seed_dir in enumerate(seed_dirs):\n",
    "        movie_dir = './videos/{}/{}'.format(environment,exp_name)\n",
    "        if not os.path.exists(movie_dir):\n",
    "            os.mkdir(movie_dir)\n",
    "        movie_file = movie_dir+'/{}.mp4'.format(seed)\n",
    "        if(not os.path.isfile(movie_file)):\n",
    "            log_dir = seed_dir\n",
    "            config_file = glob(log_dir+'*.txt')[0]\n",
    "            # with open(config_raw[0],'r') as inf:\n",
    "            #     k = inf.read()\n",
    "            #     l = re.search(r'<.*<.*.>.*>',k).group(0)\n",
    "            #     env = l.split('<')[-1].split('.')[0]\n",
    "            #     readable = re.sub(r'<.*>',\"\\\"\\\"\",k)\n",
    "            # #     k = k.replace('0x','')\n",
    "            # #     k = k.replace('<',\"\\\"\")\n",
    "            # #     k = k.replace('>',\"\\\"\")\n",
    "\n",
    "            #     dict_from_file = eval(readable)\n",
    "            processed_dict,overrides,logdir,ctrl_args,env_name = process_config_txt(config_file,log_dir)\n",
    "            ctrl_args = DotMap(**{key: val for (key, val) in ctrl_args})\n",
    "            cfg = create_config(env_name,\"MPC\", ctrl_args, overrides, logdir)\n",
    "            cfg.exp_cfg.exp_cfg.policy = MPC(cfg.ctrl_cfg)\n",
    "\n",
    "\n",
    "            cfg.exp_cfg.misc = copy.copy(cfg)\n",
    "            exp = MBExperiment(cfg.exp_cfg)\n",
    "            if(env_name != 'halfcheetah'):\n",
    "                print('this is ',env_name)\n",
    "                env = exp.env._env\n",
    "                exp.agent.env.metadata = env.metadata\n",
    "                exp.agent.env.render = env.render\n",
    "    #             print(exp.agent.env._env_info['max_length'])\n",
    "    #             exp.agent.env = env\n",
    "    #             exp.agent.env render= env.\n",
    "            else:\n",
    "                print('we are working with {}'.format(env_name))\n",
    "                env = exp.env\n",
    "\n",
    "\n",
    "            # env.place_model = place_model\n",
    "    #         model = env.model\n",
    "    #         if(environment == 'gym_hopper'):\n",
    "    #             exp.agent.sample(horizon = 100000,policy = exp.policy,record_fname = movie_file)\n",
    "    #         else:\n",
    "            exp.agent.sample(horizon = 1000,policy = exp.policy,record_fname = movie_file)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            print('movie file = {} already exists'.format(movie_file))\n",
    "#         break\n",
    "#     if(environment == 'gym_hopper'):\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
